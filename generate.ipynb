{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85506f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from generate import generate_text\n",
    "from util import encode_text\n",
    "from config import load_config\n",
    "\n",
    "from fate_lstm import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241b8a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING LSTM\n",
      "Prologue. Ryuudou ghost story\n",
      "He said he was afraid of the night.\n",
      "\"―――――――――――――\"\n",
      "Sakura to prove the dojobident, she is too words are going to be a hope of the start.\n",
      "\"But it is a single say my ideal.\n",
      "It's an instant\n",
      "supposes myself down out.\n",
      "Ilyasviel and shadow suffering to this house for because she was basically two with something\n",
      "above a sharp of a magus with this concern's\n",
      "scoller, but even I think that in a shadow gwet's should be small off as a way to find our even been suppidently left appears are extra temperated for\n",
      "me to stop it, prepared and repair the boy to know apologizing any way.\n",
      "I took a second true.\n",
      "\"――――――――!\n",
      "...Are the only one who I wounded in the enemy's victory.\n",
      "\"――――\"\n",
      "My time housen-shiers will be an infortunate to you,\n",
      "so you know he saw show.\n",
      "\"―――I don't think what I thought I've already compared since you cannot move into natural for you to take so\n",
      "what I'm all right, there's no soon, and the shadow is first in the pain, and the milike councides and I was the one in the gate with a big breakfast here, and him where she \n"
     ]
    }
   ],
   "source": [
    "input_file = 'data/fsn_script.txt'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoded_text, vocab_size, char_to_idx, idx_to_char = encode_text(input_file)\n",
    "\n",
    "### Load the right config\n",
    "config_path = 'test/LSTM_217e1e1f-0075-4974-ace4-13a4f1db1248/config_24ea4708-ed02-47a9-bf1d-038b9cb9e60c.yaml'\n",
    "model_path = 'test/LSTM_217e1e1f-0075-4974-ace4-13a4f1db1248/LSTM_seqlen16_24ea4708-ed02-47a9-bf1d-038b9cb9e60c.pth'\n",
    "\n",
    "config = load_config(config_path)\n",
    "\n",
    "if config['model'] == 'LSTM':\n",
    "    print(\"TRAINING LSTM\")\n",
    "    model = LSTMModel(vocab_size, config['embed_size'],\n",
    "                                config['hidden_size'],\n",
    "                                config['num_layers']).to(device)\n",
    "elif config['model'] == 'LSTM_NO_FORCING':\n",
    "    print(\"TRAINING LSTM WITHOUT TEACHER FORCING\")\n",
    "    model = LSTMModelNoTeacherForcing(vocab_size, config['embed_size'],\n",
    "                                config['hidden_size'],\n",
    "                                config['num_layers']).to(device)\n",
    "else:\n",
    "    print(\"Config Exception: please specify model type as \\'LSTM\\' or \\'LSTM_NO_FORCING\\'\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "generated = generate_text(model, device, char_to_idx, idx_to_char, max_len=1000, temp=0.8)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd208c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
