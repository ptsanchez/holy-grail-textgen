model: 'LSTM_NO_FORCING'

embed_size: 50

hidden_size: 50

num_layers: 2

seq_len: 64

epochs: 10

learning_rate: 0.0001

weight_decay: 0.01

early_stop_epochs: 3

patience: 3